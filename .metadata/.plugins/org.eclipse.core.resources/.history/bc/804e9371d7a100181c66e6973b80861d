package crawler.imageDownload;

import java.util.List;
import java.util.ArrayList;

import org.apache.http.impl.client.CloseableHttpClient;
import org.apache.http.impl.client.HttpClients;

import model.ImgModel;
import util.UrlUtil;
import util.ImageParser;
import util.BaiduImgParser;
import util.GoogleImgParser;
import store.LocalStorage;
import store.PreProcess;
import store.SQLStorage;

public class App {
	private static String searchEngine = "google";
	private static String keyword = "梅根福克斯";
	private static int pageNumber = 2;		
	private static String storageAdr = "/Users/RaindragonD/Desktop/Java/Crawler/imageDownload/database/"+keyword;
	
	public static void main(String[] args) throws Exception { 
	    // Create a new client and a list
		CloseableHttpClient client = HttpClients.createDefault();
		List<ImgModel> imgs = new ArrayList<ImgModel>();
		ImageParser parser = null;
		
		switch (searchEngine) {
		default:
		case "google":
			parser = new GoogleImgParser(keyword, pageNumber);
			break;		
		case "baidu":
			parser = new BaiduImgParser(keyword, pageNumber);
			break;
		}
		
		String query = parser.generateQuery();
		String source = UrlUtil.parseUrl(client,query);
		imgs = parser.getData(source);
		
		/*
		List<ImgModel> imgs_temp = null;
		
		for (int i=1;i<=pageNumber;i++) {
			String targetUrl = url1+i*30+url2+Integer.toHexString(i*30);
		    try {
				imgs_temp = UrlUtil.parseUrl(client,targetUrl);
			}
		    catch (Exception e) {
				e.printStackTrace();
			}		   
	    	for (int j=0;j<imgs_temp.size();j++) {imgs.add(imgs_temp.get(j));}
		}
		*/
		
		// DownloadImages and save to SQL; package storage
		PreProcess.modName(PreProcess.delRptImg(imgs));
		LocalStorage.download(imgs,storageAdr);
		//SQLStorage.executeInsert(imgs);
	}
}
